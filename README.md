# CAOM: Change-Aware Online 3D Mapping with Heterogeneous Multi-Beam and Push-Broom LiDAR Point Clouds


A standard style for README files

Your README file is normally the first entry point to your code. It should tell people why they should use your module, how they can install it, and how they can use it. Standardizing how you write your README makes creating and maintaining your READMEs easier. Great documentation takes work!

This repository contains:

1. [The specification](spec.md) for how a standard README should look.
2. A link to [a linter](https://github.com/RichardLitt/standard-readme-preset) you can use to keep your README maintained ([work in progress](https://github.com/RichardLitt/standard-readme/issues/5)).
3. A link to [a generator](https://github.com/RichardLitt/generator-standard-readme) you can use to create standard READMEs.
4. [A badge](#badge) to point to this spec.
5. [Examples of standard READMEs](example-readmes/) - such as this file you are reading.

Standard Readme is designed for open source libraries. Although itâ€™s [historically](#background) made for Node and npm projects, it also applies to libraries in other languages and package managers.


## Table of Contents

- [Abstract](#abstract)
- [Install](#install)
- [Usage](#usage)
	- [Generator](#generator)
- [Badge](#badge)
- [Example Readmes](#example-readmes)
- [Related Efforts](#related-efforts)
- [Maintainers](#maintainers)
- [Contributing](#contributing)
- [License](#license)

## Abstract

A High-Definition (HD) map is an essential component not only for autonomous vehicles but also for surveyors in favor of city management. Moreover, the HD map must be up-to-date by reflecting environmental changes continuously. The development of LiDAR Simultaneous Localization And Mapping (SLAM) techniques has provided an effective way to collect precise point clouds for the construction of HD maps, while traditional methods are time-consuming and labor-intensive on account of the complex street scene. Furthermore, life-long 3D mapping is quite necessary and challenging nowadays. In this paper, we introduce a novel change-aware 3D online mapping framework CAOM, using point clouds collected by Multi-Beam LiDAR (MBL) and Push-Broom LiDAR (PBL) for rapid city map update and change detection. Concerning the prior map with higher precision, heterogenous fusion is performed to rectify the SLAM drift, based on the View-Traced Clouds (ViTC) derived according to their view in common. Meanwhile, corresponding virtual range images are integrated with distance images to detect the 3D changes between the current map and the historical reference map offline. The detection results are later fused in a probabilistic way along with the homogeneous fusion process where a resilient graph consisting of diverse factors is established to maintain the local and global consistency of the final point cloud map. Compared with 3D-CSTM, the real-world experiments have shown an average 0.5 m and max 1.5 m improvement in the ATE (Absolute Translation Error) of the trajectory generated by our system. Quantitative measurements on the individual point accuracy are also conducted to verify the performance of 3D mapping with up to 16% improvement in comparison with respect to the 3D-CSTM method. The effects of the disparity detection and probabilistic fusion can be revealed from the small objects distinguished in the point cloud map as well as >95% overall accuracy. A High-Definition (HD) map is an essential component not only for autonomous vehicles but also for surveyors in favor of city management. Moreover, the HD map must be up-to-date by reflecting environmental changes continuously. The development of LiDAR Simultaneous Localization And Mapping (SLAM) techniques has provided an effective way to collect precise point clouds for the construction of HD maps, while traditional methods are time-consuming and labor-intensive on account of the complex street scene. Furthermore, life-long 3D mapping is quite necessary and challenging nowadays. In this paper, we introduce a novel change-aware 3D online mapping framework CAOM, using point clouds collected by Multi-Beam LiDAR (MBL) and Push-Broom LiDAR (PBL) for rapid city map update and change detection. Concerning the prior map with higher precision, heterogenous fusion is performed to rectify the SLAM drift, based on the View-Traced Clouds (ViTC) derived according to their view in common. Meanwhile, corresponding virtual range images are integrated with distance images to detect the 3D changes between the current map and the historical reference map offline. The detection results are later fused in a probabilistic way along with the homogeneous fusion process where a resilient graph consisting of diverse factors is established to maintain the local and global consistency of the final point cloud map. Compared with 3D-CSTM, the real-world experiments have shown an average 0.5 m and max 1.5 m improvement in the ATE (Absolute Translation Error) of the trajectory generated by our system. Quantitative measurements on the individual point accuracy are also conducted to verify the performance of 3D mapping with up to 16% improvement in comparison with respect to the 3D-CSTM method. The effects of the disparity detection and probabilistic fusion can be revealed from the small objects distinguished in the point cloud map as well as >95% overall accuracy. 

## Install

This project uses [node](http://nodejs.org) and [npm](https://npmjs.com). Go check them out if you don't have them locally installed.

```sh
$ npm install --global standard-readme-spec
```

## Usage

This is only a documentation package. You can print out [spec.md](spec.md) to your console:

```sh
$ standard-readme-spec
# Prints out the standard-readme spec
```

### Generator

To use the generator, look at [generator-standard-readme](https://github.com/RichardLitt/generator-standard-readme). There is a global executable to run the generator in that package, aliased as `standard-readme`.

## Badge

If your README is compliant with Standard-Readme and you're on GitHub, it would be great if you could add the badge. This allows people to link back to this Spec, and helps adoption of the README. The badge is **not required**.

[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen.svg?style=flat-square)](https://github.com/RichardLitt/standard-readme)

To add in Markdown format, use this code:

```
[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen.svg?style=flat-square)](https://github.com/RichardLitt/standard-readme)
```

## Example Readmes

To see how the specification has been applied, see the [example-readmes](example-readmes/).

## Related Efforts

- [Art of Readme](https://github.com/noffle/art-of-readme) - ðŸ’Œ Learn the art of writing quality READMEs.
- [open-source-template](https://github.com/davidbgk/open-source-template/) - A README template to encourage open-source contributions.

## Maintainers

[@RichardLitt](https://github.com/RichardLitt).

## Contributing

Feel free to dive in! [Open an issue](https://github.com/RichardLitt/standard-readme/issues/new) or submit PRs.

Standard Readme follows the [Contributor Covenant](http://contributor-covenant.org/version/1/3/0/) Code of Conduct.

### Contributors

This project exists thanks to all the people who contribute. 
<a href="https://github.com/RichardLitt/standard-readme/graphs/contributors"><img src="https://opencollective.com/standard-readme/contributors.svg?width=890&button=false" /></a>


## License

[MIT](LICENSE) Â© Richard Littauer
